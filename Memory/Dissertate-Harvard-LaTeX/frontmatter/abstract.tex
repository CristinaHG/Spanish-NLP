%!TEX root = ../dissertation.tex
% the abstract

En este trabajo se presenta una implementación en \textsc{Scala} de tres algoritmos que desarrollan tres fases iniciales y fundamentales en tareas de procesamiento del lenguaje natural. En primer lugar se presenta un algoritmo de tokenización que en tres fases extraerá los tokens presentes en un texto dado y las frases del mismo. En segundo lugar, se presenta un POS tagger que etiquetará todas las palabras extraídas en el algoritmo anterior atendiendo a su categoría morfosintáctica, usando el formato de etiquetas \textsf{Parole} por defecto. Para ello aplicará reglas léxicas, morfológicas y contextuales, estas últimas obtenidas mediante un algoritmo de aprendizaje sencillo. En tercer y último lugar se presenta un lematizador que pasará cada palabra a su forma base, haciendo uso de las etiquetas presentes en las mismas como consecuencia del proceso anterior para desencadenar unas u otras reglas de lematización. 
\newline
Las tres herramientas se desarrollan para el español, siguiendo la metodología de test orientados a desarrollo (TDD) y obteniendo resultados similares y en casos, ligeramete superiores a la implementación original propuesta en la versión para español de estas herramientas en\textsc{Pattern.es}. Por último, se integran las tres herramientas en un parseador, por lo que es posible probar cualquiera o todos los algoritmos desde línea de comandos. 




%\newline

