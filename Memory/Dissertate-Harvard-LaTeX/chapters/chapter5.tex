%!TEX root = ../dissertation.tex
\chapter{Implementación y pruebas}
\label{conclusion}

En este capítulo se explican la implementaciones llevadas a cabo en este trabajo y las pruebas que se han realizado sobre las mismas. Los algoritmos por se describen por orden en el pipeline. 
\section{Tokenizador}
El proceso de tokenización implementado recibe como entrada una cadena de texto y da como salida los tokens de la cadena. Si la cadena se compone de varias frases, entonces da como salida el texto segmentado en frases tokenizado. Por ejemplo, si recibe como entrada: \newline
\begin{center}\texttt{"El cielo es azul. El agua es transparente y las amapolas son rojas."}
\end{center}
Dará como salida:
 \texttt{["El", "cielo", "es", "azul", "."]} \newline
\texttt{["El", "agua", "es", "transparente", "y", "las", "amapolas", "son", "rojas", "."]}\newline
El algoritmo de tokenizado se puede dividir en 4 fases:
\begin{enumerate}
\item Preprocesado el string: manejo de comillas (simples y dobles), espacios en blanco, retornos de carro, saltos de línea.
\item Obtención de los tokens del texto
\item Separación de frases
\item Manejo de sarcasmo y emoticonos
\end{enumerate}

Tanto el algoritmo como las estructuras usadas por éste se implementan en una clase \textcolor{SchoolColor}{Tokenizer}. Igual se ha hecho con el resto de clases, pretendiendo así aislar todo la funcionalidad relativa a una clase en la implementación de la misma. Veamos el algoritmo en detalle:
\subsection{Preprocesado del texto recibido}
\begin{minted}
[frame=lines,
framesep=1mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
def find_tokens(string:String):List[List[String]]={
    var s=string
    val punc=punctuation.replace(".","").toCharArray

  //handle unicode quotes
    if(s.contains("“")) s.replace("“"," “ ")
    if(s.contains("”")) s.replace("”"," ” ")
    if(s.contains("‘")) s.replace("‘"," ‘ ")
    if(s.contains("’")) s.replace("’"," ’ ")
   //collapse whitespace
    s="""\r\n""".r.replaceAllIn(s,"\n")
    s="""\n{2,}""".r.replaceAllIn(s,EOS)
    s="""\s+""".r.replaceAllIn(s," ")
\end{minted}
Donde \textsf{punctuation} es una cadena con signos de puntuación, que se define dentro de la clase como: 
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
  private[this] val punctuation = ".,;:!?()[]{}`'\"@#\$^&*+-|=~_"
\end{minted}
En la segunda línea de la función se elimina el punto de entre los signos de puntuación, dado que el punto lo manejaremos aparte, para evitar confusiones como creer que \textsf{"..."} es un final de frase al leer su primer punto. Con eso se construye un array de caracteres \textsf{punc}. \newline
El siguiente paso es espaciar las comillas del texto, ya que el tokenizador busca tokens entre espacios en blanco. Por ejemplo, la frase:  \texttt{Como dice la canción,"vive y sé feliz".} Quedaría:  
\texttt{Como dice la canción, " vive y sé feliz " .} \newline
Finalmente se hace uso de expresiones regulares para sustituir la presencia de \textsf{\escape{r}\escape{n}}, que es el separador de línea que suele usar Windows por un salto de línea, así como cambiar uno o más caracteres en blanco por uno solo y dos o más saltos de línea por \textsf{EOS}, definida anteriormente dentro de la clase como:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
  private[this] val EOS = "END-OF-SENTENCE"
\end{minted}

\subsection{Obtención de los tokens}
Para obtener los tokens se define el token con una expresión regular de la siguiente forma:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
private[this] var TOKEN="""(\S+)\s""".r
\end{minted}
Es decir, uno o más caracteres que no sean espacios en blanco seguidos de un espacio en blanco. Ésta expresión regular se usa para encontrar todas las coincididencias de palabras seguidas de un espacio en blanco en el texto, en este caso \textsf{s}. Luego, se itera sobre cada una de las coincidencias encontradas de la siguiente manera: \newline
Se comienza eliminando el espacio en blanco final de la palabra: por ejemplo \textsf{"gatos "} $\Rightarrow$ \textsf{"gatos"}, y se comprueba si la primera letra de la palabra es un signo de puntuación distinto del punto. Si lo es, se quita la primera letra de la palabra y se mete en la lista de tokens, repitiendo el mecanismo hasta que la primera letra de la palabra no sea un signo de puntuación. Después comienza de nuevo un proceso iterativo, en el que se comprueba si la última letra de la palabra es un signo de puntuación, incluido el punto. Aquí pueden darse tres casos:
\begin{itemize}
\item Si el final de la palabra son puntos suspensivos: Por ejemplo \textsf{"cantaba..."} en este caso  se quitan los tres puntos finales y se añaden a una lista para ser añadidos después.
\item Si el final de la palabra es un signo de puntuación pero no es ningún punto: se quita el signo de puntuación y se añade a una la lista, para ser añadido después.
\item Si la palabra acaba con un punto: en ese caso se comprueba si es una abreviación (Por ejemplo: Srta.) para ello se hace uso de una lista de abreviaciones y expresiones regulares definidos en la clase: 
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 private[this] val abbreviations=List("a.C.", "a.m.", "apdo.", "aprox.", "Av.", "Avda.", "c.c.", "D.", "Da.", "d.C.",
    "d.j.C.", "dna.", "Dr.", "Dra.", "esq.", "etc.", "Gob.", "h.", "m.n.", "no.",
    "núm.", "pág.", "P.D.", "P.S.", "p.ej.", "p.m.", "Profa.", "q.e.p.d.", "S.A.",
    "S.L.", "Sr.", "Sra.", "Srta.", "s.s.s.", "tel.", "Ud.", "Vd.", "Uds.", "Vds.",
    "v.", "vol.", "W.C.")

private[this] val re_abbr1="""^([A-Za-z]\.)+\$""".r 
private[this] val re_abbr2="""^[A-Z][a-z]{1,3}\.\$""".r 
\end{minted}
donde \textcolor{SchoolColor}{re\_abbr1} empareja abreviaciones como \textsf{D.,U.S.,c.c.}, 
y \textcolor{SchoolColor}{re\_abbr2} empareja abreviaciones como \textsf{Dr.,Sr.,Dra.,Uds.}.
Si se reconoce como abreviación, se mete en la lista de tokens, mientras que si no es una abreviación se quita el punto y se añade a una la lista, para ser añadido después.
\item finalmente se añaden tanto la palabra como el signo de puntuación que se ha ido guardando para después en la lista de tokens. La desripción en código es la siguiente:
\end{itemize}   

\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
var tokens=List[String]()

  //get tokens and handle punctuation marks
  TOKEN.findAllIn(s+" ").foreach(t => if(t.length>0){
   var tail=mutable.MutableList[String]()
   var t2=t.stripSuffix(" ")
   while (punc.contains(t2.head)){
    tokens::=t2.head.toString
    //tokens=tokens.reverse
    t2=t2.tail
   }
   breakable {
    while (punc.contains(t2.last) || t2.endsWith(".")) {
     if (t2.endsWith("...")) {
      tail += ("...")
      t2 = t2.substring(0, t2.length - 3)
     }
     else if (punc.contains(t2.last)) {
      tail += (t2.substring(t2.length - 1))
      t2 = t2.substring(0, t2.length - 1)
     } //split elipsis (...) before splitting period

     //split period(if not an abbreviation)
     if (t2.endsWith(".")) {
      if ((abbreviations.contains(t2) || re_abbr1.findAllMatchIn(t2).length > 0 || re_abbr2.findAllMatchIn(t2).length > 0) != true) {
       tail += (t2.substring(t2.length - 1))
       t2 = t2.substring(0, t2.length - 1)
      }else break()
     }
    }
   }

   if( t2.compareTo("")!=0){
    tokens::=t2
   }
   if(!tail.isEmpty) {
    tail.foreach(u=> tokens::=u.toString )
   }
  })
\end{minted}
 Puesto que en el código se ha ido insertando por la cola, sólo quedaría invertir la lista para tener los tokens:
 \begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 tokens=tokens.reverse
\end{minted}
\subsection{Separación de frases} 
Obtenida la lista de tokens, queda segmentarla por frases. El procedimiento es el siguiente: se itera sobre la lista de tokens obtenida, comprobando si el token es algún signo de fin de sentencia \textsf{("...",".","!","?","EOS")}. Cuando se encuentra un signo de fin de sentencia, se toman todos los tokens leídos (incluído el de final de sentencia) como una frase. A partir de aquí empieza a considerarse que empieza la frase siguiente. El proceso termina cuando se ha iterado sobre todos los tokens. Su descripción en código, es:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
  var j=0
  var i=0
  var sentences=List[String]()
   while (j < tokens.length) {

    if (tokens(j) == "..." || tokens(j) == "." || tokens(j) == "!" || tokens(j) == "?" || tokens(j) == EOS) {
     j += 1
     sentences ::= tokens.slice(i, j).filter(t => t != EOS).mkString(" ")
     i = j
    }
    j += 1
   }
  sentences::=tokens.slice(i,j).filter(t=>t!=EOS).mkString(" ")
\end{minted}
Hay frases que no tienen signo de puntuación final. Se podría considerar que si no tiene signo de puntuación final no está bien estructurada y por lo tanto no es válida, pero se ha preferido considerar que si no tiene signo de puntuación final, la frase se acaba cuando no hay más tokens. Por ejemplo \texttt{"Ese boli negro escribe muy bien"} se entendería como una única frase. Debido a esto, se añade la última línea de código anterior, ya fuera del bucle. Para textos bien estructurados (con frases con una marca de fin) esta sentencia última resulta en añadir un sentencia vacía al conjunto de sentencias, sin embargo esta se filtra antes de devolver el resultado de forma muy cómoda en \texttt{Scala}. \newline   
\subsection{Manejo de sarcasmo y emoticonos} 
Finalmente, se aplican las expresiones regulares para señalizar una posible muestra de  sarcasmo y el manejo de emoticonos y se devuelve el resultado como lostas de listas de cadenas, es decir, como una lista de frases.
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 sentences=sentences.map(s=>re_sarcasm.replaceAllIn(s,"(!)"))
  sentences=sentences.map(s=> RE_EMOTICONS.replaceAllIn(s, m=> s"\${m.group(1).replace(" ","")+m.group(2)}"))
  return sentences.reverse.filter(s=> !s.isEmpty).map(t => t.split(" ").toList)
\end{minted}
donde \textcolor{SchoolColor}{re\_sarcasm} se define arriba como:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
private[this] val re_sarcasm="""\( ?\! ?\)""".r
\end{minted}
y \textcolor{SchoolColor}{RE\_EMOTICONS} como:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
private[this] val emoticons= mutable.Map[(String,Double),List[String]]()
  emoticons+=(("love" , 1.00) ->List("<3","♥"))
  emoticons+=(("grin" , 1.00)->List(">:D", ":-D", ":D", "=-D", "=D", "X-D", "x-D", "XD", "xD", "8-D"))
  emoticons+=(("taunt", +0.75)->List(">:P", ":-P", ":P", ":-p", ":p", ":-b", ":b", ":c)", ":o)", ":^)"))
  emoticons+=(("smile", +0.50)->List(">:)", ":-)", ":)", "=)", "=]", ":]", ":}", ":>", ":3", "8)", "8-)"))
  emoticons+=(("wink" , +0.25)->List(">;]", ";-)", ";)", ";-]", ";]", ";D", ";^)", "*-)", "*)"))
  emoticons+=(("gasp" , +0.05)->List(">:o", ":-O", ":O", ":o", ":-o", "o_O", "o.O", "°O°", "°o°"))
  emoticons+=(("worry", -0.25)->List(">:/",  ":-/", ":/", ":\\", ">:\\", ":-.", ":-s", ":s", ":S", ":-S", ">.>"))
  emoticons+=(("frown", -0.75)->List(">:[", ":-(", ":(", "=(", ":-[", ":[", ":{", ":-<", ":c", ":-c", "=/"))
  emoticons+=(("cry"  , -1.00)->List(":'(", ":'''(", ";'("))

  private[this] var re_emoticons=""::Nil
  //separating emojis by "|"
  emoticons.values.foreach(list=>re_emoticons:::=list.flatMap(elem=> if(elem.compareTo(list.last)!=0) "|"::elem::Nil else "|"::elem::"|"::Nil).tail)
  private[this] var re1_emoticons=""::Nil
  //scaping each char in icons
  re_emoticons.foreach(icon=>if(!(icon.equals("|"))) re1_emoticons::=icon.mkString("?".concat("""\""")) else re1_emoticons::=icon )
  // if letters= "D" "S" "s" "b" or "c" do not scape
  re1_emoticons=re1_emoticons.map(t=>
      if( t.contains("D")) t.dropRight(t.length-t.indexOf("D")+1)+t.last
      else if (t.contains("S")) t.dropRight(t.length-t.indexOf("S")+1)+t.last
      else if (t.contains("s")) t.dropRight(t.length-t.indexOf("s")+1)+t.last
      else if (t.contains("b")) t.dropRight(t.length-t.indexOf("b")+1)+t.last
      else if (t.contains("c")) t.dropRight(t.length-t.indexOf("c")+1)+t.last
      else t
  )
  // scape first char in emoji
  re1_emoticons=re1_emoticons.reverse.tail.map(t => if(!(t.equals("|"))) """\"""+t else t )  
  //create emoji regex
  private[this] var RE_EMOTICONS=Pattern.quote(re1_emoticons.dropRight(2).mkString).r
\end{minted}

Por último, en la clase tokenizador también se implementan dos métodos que imprimen las sentencias de tokens y cuentan las sentencias de tokens, respectivamente. 
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
def get_sentences(sentences:List[String]): Unit ={
  sentences.foreach(p=>print(p+"\n"))
 }

 def count_sentences(sentences:List[List[String]]): Int ={
  return sentences.length
 }
\end{minted} 
\section{POS Tagger}
El algoritmo de Pos tagger realiza el etiquetado morfosintáctico del texto. Para ello recibe una lista de tokens y devuelve una lista de tuplas (token, etiqueta) de los mismos. Para el etiquetado se usan etiquetas en el formato de \textsc{Parole} \url{http://www.lsi.upc.edu/~nlp/SVMTool/parole.html} , pero se añade opción de especificar una función que las mapee a otro formato como PennTreebank o el formato universal. \newline
Los parámetros que recibe el algoritmo son: 
\begin{itemize}
\item una lista de tokens
\item un objeto de la clase léxico
\item un objeto de la clase morfología
\item un objeto de la clase contexto
\item una lista de string con tres etiquetas por defecto("NCS","NP","Z")
\item una función para mapear el formato de las etiquetas a otro formato(opcional)
\end{itemize}

El funcionamiento es el siguiente: 
\begin{enumerate}
\item Etiquetado inicial: se itera sobre los tokens, etiquetando las palabras conocidas. Para ello se buscan en el diccionario de léxico que se especifica por parámetro, asignándole la etiqueta que dicha palabra tenga el diccionario léxico. Si no se encuentra la palabra en el diccionario, esta se etiqueta como \texttt{"None"} en esta primera fase del algoritmo.
\item Etiquetar las desconocidas: para ello se itera sobre la colección obtenida en el paso anterior. Si una palabra tiene etiqueta desconocida pero es una palabra que empieza por mayúscula, se cambia su etiqueta a \texttt{"NP"} (nombre propio). Si por el contrario, casa con la expresión regular:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 private[this] val CD = """^[0-9\-\,\.\:\/\%\$]+\$"""
 \end{minted}
 es decir, es un dígito, símbolo o combinación de ambos, se etiqueta como \texttt{"Z"} (dígito). Si se ha proporcionado una morfología al algoritmo, se aplican las reglas morfológicas presentes en la misma para cambiar la etiqueta de la palabra. Por último, si ninguna de las anteriores aplica, se etiqueta como \texttt{"NCS"}.
 \item Aplicación de reglas contextuales: Si se ha especificado un contexto, éste se aplica para mejorar el etiquetado anterior de todas las palabras.
 \item Si se ha especificado una función para mapear las etiquetas a otro formato, ésta se aplica sobre el resultado anterior.   
\end{enumerate} 
El algoritmo en código se encuentra dentro de la clase \textcolor{SchoolColor}{PosTagger} y es el siguiente:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
def find_tags(tokens:List[String], lexicon:Lexicon, morphology:Morphology, context:Context, default:List[String],
                mapCall:(String,String)=>(String,String)):List[(String,String)]={

    var tagged=List[(String,String)]()
    var taggedMorp=List[(String,String)]()
    var taggedCntxt=List[(String,String)]()
    var taggedfin=List[(String,String)]()
    // Tag known words.
    tokens.foreach(t=> tagged::=(t,lexicon.getLexDict.getOrElse(t,lexicon.getLexDict.getOrElse(t.toLowerCase,"None"))))
    //Tag unknow words
    tagged=tagged.reverse
    taggedMorp=tagged.map(t=> {
      var prev = ("None", "None")
      var next = ("None", "None")
      if (tagged.indexOf(t) > 0) prev = tagged(tagged.indexOf(t) - 1)
      if (tagged.indexOf(t) < (tagged.length - 1)) next = tagged(tagged.indexOf(t) + 1)
      if (t._2 == "None") {
        //use NP for capitalized words
        if (t._1.matches("""^[A-Z][a-z]+.\$""")) (t._1, default(1))
        //use CD for digits and numbers
        else if (t._1.matches(CD)) (t._1, default(2))
        //use suffix rules (ej, -mente=ADV)
        else if (!morphology.getMorphology.isEmpty) (t._1,morphology.apply(t._1, default(0), prev, next, lexicon.getLexDict))
          // Use most frequent tag (NCS).
        else (t._1, default(0))

      } else (t._1,t._2)
    })
    //Tag words by context
    if(!context.getContextList.isEmpty ) taggedCntxt=context.apply(taggedMorp)
    else taggedCntxt=taggedMorp
    //Map tag with a custom function
    if(mapCall != null){
      taggedCntxt.foreach(t => taggedfin ::= mapCall(t._1, t._2))
      taggedfin=taggedfin.reverse
    } else taggedfin=taggedCntxt
    return taggedfin
  }
\end{minted}

\subsection{Aplicación del léxico}
En la clase \textcolor{SchoolColor}{Lexicon} se implementa un método que lee el fichero \textcolor{SchoolColor}{es-lexicon.txt} y crea un Diccionario Léxico como dato miembro de la clase. La cabecera del método de lectura es la siguiente:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 def read(path: String, encoding: String, comment: String): Unit
\end{minted}
recibiendo como parámetros la ruta del fichero, la codificación y el formato de los comentarios del mismo. La aplicación del léxico en el método anterior es trivial, pues no es más que consultar un diccionario.
\subsection{Aplicación de la morfología}
En la clase \textcolor{SchoolColor}{Morphology} se implementa un método que lee el fichero \textcolor{SchoolColor}{es-morphology.txt} y crea una lista interna a la clase de reglas morfológicas (\textsf{morphologyList}). La cabecera es igual que la descrita justo arriba. En esta clase se los comandos de las reglas morfológicas, teniendo en cuenta los prefijos-sufijos de las palabras, como: 
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
private [this] var rulesSet= Set(
    "word", // Word is x.
    "char", // Word contains x.
    "haspref", // Word starts with x.
    "hassuf", // Word end with x.
    "addpref", // x + word is in lexicon.
    "addsuf", // Word + x is in lexicon.
    "deletepref", // Word without x at the start is in lexicon.
    "deletesuf", // Word without x at the end is in lexicon.
    "goodleft", // Word preceded by word x.
    "goodright"// Word followed by word x.
  )
   rulesSet.foreach(r=> rulesSet.+=("f"+r.mkString))
\end{minted}
Estas reglas se emplean en el método \textcolor{SchoolColor}{apply} de esta clase, que aplica la morfología a un par \newline (palabra,etiqueta), dado el par previo a la misma de (palabra,etiqueta), y el posterior. \newline
El proceso es éste: se itera sobre la lista de reglas extraídas del fichero (\textsf{morphologyList}), y se comprueba si el comando de la regla está en \textsf{rulesSet}. Las reglas son del tipo:  \texttt{ly hassuf 2 RB x} o  \texttt{NN s fhassuf 1 NNS x}, donde el comando es \textsf{"hassuf y fhassuf"} respectivamente. Luego se aplican las reglas de \textsf{rulesSet} a la palabra que se quiere etiquetar y si se cumple alguna, se cambia la etiqueta de la palabra a la que indique la regla actual de \textsf{morphologyList}.
El proceso en código es:
\begin{minted}
[frame=lines,
framesep=1.3mm,
fontsize=\footnotesize,
breaklines=true
]{scala}
 def apply(token:String,tag:String,previus:(String,String), next:(String,String),lexicon:mutable.Map[String,String]): String ={

    var f = false
    var x =""
    var cmd=""
    var pos=""
    var realTag=""

    morphologyList.foreach(l=> {
      if (rulesSet.contains(l(1))) { // Rule = ly hassuf 2 RB x
        f = false
        x = l(0)
        pos = l(l.length - 2)
        cmd = l(1).toLowerCase
      }
      if (rulesSet.contains(l(2))) { // Rule = NN s fhassuf 1 NNS x
         f = true
         x = l(1)
         pos= l(l.length -2)
         cmd= l(2).toLowerCase.stripPrefix("f")
      }
      if( f==false || tag.compareTo(l(0))==true){
        if((cmd=="word" && x==token) ||
          (cmd=="char" && token.contains(x)) ||
          (cmd=="haspref" && token.startsWith(x)) ||
          (cmd=="hassuf" && token.endsWith(x)) ||
          (cmd=="addpref" && lexicon.contains(x+token)) ||
          (cmd=="addsuf" && lexicon.contains(token+x)) ||
          (cmd=="deletepref" && token.startsWith(x) && lexicon.contains(token.substring(x.length))) ||
          (cmd=="deletesuf" && token.endsWith(x) && lexicon.contains(token.substring(0,token.length-x.length))) ||
          (cmd=="goodleft" && x==next._1) ||
          (cmd=="goodright" && x==previus._1)
        ){
          realTag=pos
        }
      } else realTag=tag
    })
    return realTag
  }
\end{minted}
