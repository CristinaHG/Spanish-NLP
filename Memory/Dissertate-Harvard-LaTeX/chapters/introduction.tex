%!TEX root = ../dissertation.tex
\chapter{Introducción y motivación}
\label{introducción}
\section{Introducción al PLN}
El proyecto desarrollado se engloba en el campo del Procesamiento del lenguaje natural(PLN). El lenguaje natural es cualquier lenguaje usado por los humanos para comunicarse (Alemán, Inglés, Español, Hindi...). Dado que estos lenguajes se transmiten entre generaciones y van experimentando evoluciones, resulta difícil obtener reglas que los describan. PLN es, por tanto, el área de estudio y aplicación que engloba cualquier tipo de manipulación computacional del lenguaje natural.\newline Es decir, PLN abarca desde aplicaciones simples, como contar el número de ocurrencias de las palabras en un texto para comparar diferentes estilos de escritura, a aplicaciones más complejas, como comprender expresiones humanas completas para poder dar respuestas útiles a preguntas. \citet{bird2009natural} Como por ejemplo, el asistente Siri de iPhone. 

La lingüística computacional o PLN comenzó en 1980, sin embargo en los últimos 20 años ha crecido enormemente, despertando un gran interés en el ámbito de la investigación científica pero también en el ámbito práctico, ya que cada vez son más los productos, especialmente los tecnológicos, que incorporan algún tipo de aplicación basada en NLP. Por ejemplo, traductores como el traductor de Skype, o asistentes de voz inteligentes (Cortana de Microsoft, Google Now de Google o el ya mencionado Siri de Apple). \newline
Este crecimiento en el campo del procesamiento del lenguaje natural se debe principalmente a que en los últimos años, con el uso de redes sociales como Facebook, SnapChat, Twitter, Google plus, Linked in... y de sitios web comerciales como Amazon o Booking, los usuarios han generado una gran cantidad de contenido mayoritariamente subjetivo, el cual se puede aplicar en muchos ámbitos como márketing, política, gestión de crisis, soporte, atención al cliente, etc. También han influido en su crecimiento el aumento de capacidad de procesamiento y cómputo que ha habido en los últimos años y el desarrollo de técnicas de machine learning más complejas y potentes.    
\newline

En la actualidad, según lo descrito en \citet{hirschberg2015advances} éstas son algunas de las principales áreas en PLN:
\section*{Traducción automática}
La traducción automática es el área del PLN que tiene como objetivo el empleo de sofware para ayudar a traducir de un lenguaje natural a otro, ya sea en texto o hablado. Ésto supone una gran dificultad, ya que para que una traducción sea correcta, no basta con traducir palabra a palabra, sino que hay que tener en cuenta el sentido de la palabra y el contexto de ésta, pues hay casos en los que la misma palabra significa varias cosas dependiendo del contexto. Por ejemplo, en las frases \textsl{"compra una lata de refresco"} y \textsl{"deja ya de dar la lata"} aparece la  palabra \textsl{lata} desempeñando una  función distinta:\newline En la primera frase, \textsl{lata} es un nombre, por lo que se entendería como un envase hecho de hojalata, mientras que en la segunda frase aparece como una locución verbal, por lo que se entendería como "molestar" o "importunar". \newline  
El campo de la traducción automática se empezó a estudiar a finales de 1950s, sin embargo inicialmente no tuvo mucho éxito debido a que los traductores construidos eran sistemas basados en gramáticas escritas a mano. Fue a partir de 1990 y gracias a que los científicos de IBM consiguieron una cantidad suficientemente grande de frases de traducciones entre dos lenguajes, cuando construyeron un modelo probabilístico de traducción automática.\newline
A partir de entonces se siguió investigando y se descubrieron los \textcolor{SchoolColor}{traductores máquina basados en frases}, que en lugar de ir traduciendo palabra a palabra, detectaban los pequeños subgrupos de palabras que solían ir juntas y que tenían una traducción especial. Esto se utilizó para desarrollar el traductor de Google.  
\newline
Actualmente, el estado del arte en este campo está en traductores máquinas que usan deep learning, entrenando un modelo de varios niveles para optimizar un objetivo (la calidad de la traducción), donde luego el modelo pueda aprender por sí mismo más niveles que le sean útiles para desarrollar la tarea. Esto ha sido estudiado especialmente para redes neuronales, habiendo conseguido en varios casos obtener los mejores resultados hasta el momento, empleando redes neuronales distribuidas. Como por ejemplo, en  \citet{luong2014addressing}.

\section*{Sistemas de reconocimiento del habla}

Esta área, muy conocida desde 1980s, estudia como permitir y mejorar la comunicación entre humanos y máquinas. Aunque siempre se ha pensado, por ejemplo, en aplicaciones como robots que ayudan en casa o a personas con movilidad reducida,no muchos años atrás se expandió al ámbito de los smartphones (mencionábamos en la introducción a los asistentes de voz para móvil más conocidos). \newline
El reconocimiento del habla necesita principalmente de :
\begin{itemize}
\item Una herramienta de reconocimiento automático del habla (RAH) para identificar que está diciendo el humano.
\item Una herramienta de manejo de diálogo (MD) para identificar lo que quiere el humano.
\item Acciones para realizar la actividad solicitada.
\item Una herramienta de síntesis texto a voz para que la máquina pueda comunicar al humano el resultado de forma hablada.
\end{itemize}
Sin embargo, aún se está investigando como hacer estas herramientas más precisas. Añadiéndole a lo anterior las dificultades propias de reconocer lenguaje humano hablado: pausas, coletillas, coordinación, toma de turnos... desemboca en que los sistemas de reconocimiento de habla aún no han tenido gran éxito interactuando en dominios abiertos, donde los usuarios pueden hablar de cualquier cosa, aunque en dominios cerrados donde conocían el tema han mostrado resultados mejores. \newline
En los últimos años se ha aplicado deep learning en estos sistemas, mapeando señales de sonido a secuencias de palabras y sonidos del lenguaje humano \citet{hinton2012deep}, aunque actualmente el
enfoque más usado es el proceso de decisión de Markov, que hace identificación del diálogo (pregunta, sentencia, acuerdo..) mediante una probabilidad de distribución sobre todos los posibles estados del sistema, que va actualizando según se desarrolla el diálogo. \citet{young2013pomdp}.

\section*{Lectura Automática}
La lectura automática es el área que tiene como objetivo que las máquinas puedan integrar o resumir información a los humanos, mediante la lectura y comprensión de las grandes cantidades de texto disponibles. \newline
Esta idea atrae especialmente a los científicos, ya que es complicado llevar el ritmo de todas las publicaciones que se hacen, aunque sólo sea en su campo, por lo que sería de gran utilidad que un sistema pudiera resumir e identificar los datos más relevantes de las publicaciones. 
El objetivo inicial de estos sistemas es la extracción de relaciones, es decir, ser capaz de extraer relaciones entre dos entidades, como por ejemplo "A es hermano de B", lo cual ya se ha realizado con éxito en dominios específicos. Aunque hay técnicas que escriben los patrones de las relaciones a mano (por ejemplo: <PERSONA>, el hermano de <PERSONA>), se ha demostado que aplicando Machine learning se obtienen mejores resultados, ya que se pueden obtener relaciones basadas en características extraidas de secuencias de palabras y secuencias gramaticales de una frase. \citet{culotta2004dependency}.
\newline
Los sistemas más recientes han usado inferencia probabilística sofisticada para distinguir qué claúsulas textuales se asocian a qué factores de la base del conocimiento, por ejemplo,  \citet{niu2012deepdive} y apuestan por técnicas de extracción de hechos más simples pero más escalables que no requieren etiquetado manual de los datos, o las extraen usando NLP. \citet{etzioni2011open}. 

     
\section*{Minería de datos en medios sociales}
La minería de datos es el campo que tiene como objetivo descubrir patrones en grandes volúmenes de datos. Hoy en día, la gran cantidad de datos disponibles a través de redes sociales (Facebook, Twitter, Instagram, Youtube..), blogs o foros se puede descargar usando técnicas de web scrapping y se usa, aplicando técnicas de machine learning e inteligencia artificial, para aprender a detectar información demográfica a partir del lenguaje (como sexo o edad), hacer un seguimiento de las tendencias más populares u opiniones más populares sobre política o sobre productos, e incluso, como hizo Google (\url{www.google.org/flutrends/}) para ver como se difunde la gripe a través de los tweets de los usuarios y sus búsquedas en internet \citet{elhadad2014information}. \newline
A pesar de que este campo tiene innumerables aplicaciones, muchas de las cuales podrían ser de gran interés (como por ejemplo, detectar grupos que hacen bullying a otros o fomentan el odio), están aumentando los poblemas de privacidad y se está limitando el acceso a esos datos. Por ejemplo, Twitter          ya ha limitado el periodo de tiempo del que se pueden descargar tweets. Instagram también a modificado su API con este propósito. \newline
Otra dificultad  con la que cuenta este campo, es la validación. Muchas veces no hay forma de comprobar que la información presente en internet es cierta, por ejemplo las reseñas sobre hoteles, productos o restaurantes. En la actualidad, Facebook está ideando un modelo para detectar noticias falsas en su red social. Aunque se ha probado a agregar información de distintas fuentes para intentar validar la información, de momento no ha tenido mucho éxito.    
\section*{Análisis de sentimientos}
Este campo (también conocido como minería de opiniones) analiza las opiniones, sentimientos, valoraciones, actitudes y emociones de la gente frente a entidades como productos, servicios, organizaciones, individuos, eventos, temas, cuestiones...\newline
\citet{9781107017894} emplea el término \textsl{opinión} para referirse al concepto de sentimento, evaluación, valoración o actitud e información asociada (objetivo de la opinión o persona que da la opinión) en su totalidad, y el término \textsl{sentimiento} para referirse al sentido positivo o negativo subyacente en una opinión. Por ejemplo \textsl{"Apple lo está haciendo muy bien en esta economía pobre"} es una opinión que contiene dos sentimientos, uno positivo con Apple como objetivo y otro negativo sobre la economía actual.\newline
 Los estudios sobre este campo comenzaron en el año 2000, principalmente debido a que para entonces se empezó a recoger texto subjetivo en formato digital. Actualmente hay muchos campos relacionados con este cuyas tareas difieren ligeramente, por ejemplo análisis de opiniones, análisis de subjetividad, minería de sentimientos... aunque gran parte del trabajo se concentra en el análisis de sentimientos. \newline
Los enfoques más simples tratan de identificar si lo expresado en el texto (por ejemplo, en un tweet) tiene una orientación positiva o negativa usando dicccionarios de sentimientos como \citet{whissell1989dictionary}. Otros enfoques más complejos tratan de identificar la polaridad del sentimiento así como el objeto de éste.\citet{wiebe2005annotating}. También se han realizado trabajos recientes tratando de indentificar algunas emociones en particular, como las de Ekman (furia, aversión, miedo, felicidad,tristeza y sorpresa) y se ha investigado sobre reconocer esas emociones clásicas usando características como la edad, la personalidad , el género las condiciones mentales o médicas del usuario.  \citet{hirschberg2015advances}. \newline
Las aplicaciones de este campo son innumerables y abarcan desde identificar valoraciones en productos \citet{wang2015sentiment} a predecir los precios del mercado o evaluar el estado mental de una comunidad. \citet{bollen2011modeling}.
\section{Historia del PLN}
De acuerdo a lo descrito en \citet{hirschberg2015advances}, el PLN comienza en 1980s como intersección entre la inteligencia artificial y la lingüística.  
Durante las primeras décadas, los investigadores escribían a mano las reglas y el vocabulario del lenguaje humano. Sin embargo, no se obtuvo éxito, debido a la variabilidad y dificultad del lenguaje humano. Por ejemplo, el traductor palabra a palabra de ruso a inglés que no tenía en cuenta el contexto, el léxico o la morfología y que tradujo la frase bíblica : \textsl{"El espíritu está dispuesto, pero la carne es débil"} como \textsl{"El vodka es agradable, pero la carne es
estropeado"} según \citet{nadkarni2011natural}. \newline
Es a partir de 1990 cuando el PLN sufre una transformación cuando los investigadores comienzan a tener la posibilidad de obtener grandes cantidades de datos del lenguaje en formado digital y construyen modelos sobre estos. Surge así el PLN estadístico o PLN basado en corpus, lo que supuso un éxito en el uso del "big data", aunque ese término se introduciría más adelante. Con lo anterior surgen métodos que usan el \textsc{Part-Of-Speech} (POS) de las palabras, es decir, su categoría morfosintáctica( si son sustantivo, un adjetivo, un verbo, una preposición...) adquiriendo notables resultados cuando se entrena con un conjunto de datos suficientemente grande. \newline
Actualmente, muchos clasificadores de texto y sentimientos se basan únicamente en los diferentes conjuntos de palabras que presenta el texto (bolsas de palabras) sin tener en cuenta estructuras a nivel de frase, de documento o de significado. Sin embargo, los mejores enfoques actuales usan técnicas sofisticadas de machine learning y un buen entendimiento de la estructura lingüística subyacente, identificando información sintáctica, semántica y de contexto. Algunos de los sofwares más conocidos acutalmente son:\newline
\begin{itemize}
\item Stanford CoreNLP \citet{manning2014stanford} es una suite de herramientas de PLN basada en machine learning, que pueden ser incorporadas en aplicaciones con necesidades de procesamiento de texto. Desarrollada en Java y con algunas herramientas disponibles para los lenguajes más hablados, también incluye métodos para entrenar modelos sobre corpus de datos.
\item Python NLTK \citet{bird2006nltk} es una suite de PLN de las más completas. Programada en Python, soporta un gran número de librerías para texto que incluyen las herramientas más comunes. Su éxito se debe en parte a que está bien documentada, incluye tutoriales y a su comunidad activa de usuarios. 
\end{itemize}
\section{Aproximaciones más comunes en PLN} 
Debido a la gran aplicabilidad que tiene el análisis de sentimientos, se ha despertado un gran interés 
por este área del PLN, proponiendo en los últimos años numerosas aproximaciones que emplean varias técnicas desde diferentes áreas de la informática para resolver el problema. \newline
En la actualidad, las aproximaciones más comunes son dos \citet{ribeiro2016sentibench}: 
\subsection{Aplicación de métodos de machine learning supervisados}
Estos enfoques aplican métodos de clasificación supervisada, por lo que tienen como desventaja que requieren de datos (corpus) etiquetados (con información morfosintáctica, lema...) para entrenar los clasificadores, lo que resulta costoso en tiempo dado que son cantidades grandes de datos.\newline
De esta forma se consigue que los algoritmos aprendan de los datos etiquetados para luego ser capaces de clasificar otros datos de entrada. Como ventaja, estos métodos tienen la habilidad de adaptar y crear modelos entrenados para objetivos y contextos concretos.  
\subsection{Aplicación de métodos basados en léxico}
Estos enfoques tienen en común que emplean listas predefinidas de palabras, donde cada palabra está asociada a un sentimiento específico. Los métodos basados en léxico varían según el contexto en el que se crean, por ejemplo, \textsc{LIWC} \citet{tausczik2010psychological} fue originalmente propuesto para analizar patrones de sentimientos en textos formales escritos en inglés, mientras que \textsc{PANAS-t} \citet{gonccalves2013panas} fue adaptado al contexto web.\newline
A pesar de que no tienen la parte negativa de necesitar un conjunto de datos etiquetados, tienen la dificultad de crear un diccionario basado en léxico que sea aplicable en múltiples contextos. 
\section{Estado del arte}
En la sección anterior se describían las aproximaciones más comunes actualmente en el análisis de sentimientos. Ya que tenemos una idea, en esta sección se ilustra brevemente el estado del arte.\newline
En investigación, el análisis de sentimientos se ha desarrollado a tres niveles, según  \citet{9781107017894} y \citet{westerski2007sentiment} :
\subsection{Análisis de sentimientos a nivel de documento}
El objetivo de este análisis es clasificar todos los sentimientos expresados por los autores a lo largo del documento, concluyendo si lo expresado en el documento es positivo, negativo o neutro, sobre una entidad que puede ser un producto o servicio. La mayoría de las técnicas de análisis de sentimientos a nivel de documento obtienen un acierto de clasificación entre el 70\% y el 80\%,cuando son aplicadas a un solo tipo de texto, dependiendo de la cantidad de texto que se tenga como entrada y del tipo de texto. \newline
Algunos de las soluciones más destacadas en este área, son:\newline
Por una parte, el trabajo desarrollado por  \citet{turney2002thumbs} para clasificación de críticas, donde presenta un algoritmo de tres pasos que procesa los documentos sin supervisión humana. Este se basa en la medida de la distancia entre los adjetivos encontrados en el texto a palabras preseleccionadas con polaridad conocida. Brevemente, los pasos que sigue son:\newline
\begin{itemize}
\item Paso 1: Extrae los adjetivos del documento aplicando una serie de patrones predefinidos ( como nombre-adverbio, nombre-adjetivo...etc)
\item Paso 2: Mide la orientación semántica. Para ello se mide la distancia a palabras cuya polaridad se conoce ("excelente" y "pobre"). Obtiene la dependencia entre dos palabras analizando el número de ocurrencias con el motor de búsqueda \textcolor{SchoolColor}{AltaVista} para documentos que contienen dos palabras relativamente próximas. 
\item Paso 3: Finalmente cuenta la orientación semántica media para todos los pares de palabras y  clasifica la crítica como recomendada o no recomendada. 
\end{itemize}

Por otro lado, \citet{pang2002thumbs} presentaron otro trabajo basándose en técnicas conocidas de clasificación. En la propuesta se testea un grupo seleccionado de algoritmos de aprendizaje automático, comprobando si producen buenos resultados cuando se aplica el análisis de sentimientos a nivel de documento.\newline
Presentan resultados para \textsf{Naive Bayes} \citet{lewis1998naive}, \textsf{Máxima entropía} \citet{berger1996maximum} y \textsf{Máquinas de soporte vectorial} \citet{joachims1998text}, con un acierto de clasificación final de 71\%-85\%, dependiendo de la técnica y el conjunto de datos empleados.       
\subsection{Análisis de sentimientos a nivel de oración}
Dos son los objetivos de este análisis: el primero es identificar si la frase contiene opiniones (es subjetiva) u objetiva. El otro es clasificar la frase si es subjetiva, en positiva, negativa o neutral.   
Al igual que el anterior nivel de análisis descrito, la mayoría de las soluciones propuestas a nivel de oración aplican técnicas de machine learning. \newline
Entre los trabajos más conocidos centrados en encontrar frases subjetivas está\citet{riloff2003learning} donde propusieron un método que usa clasificadores de alta precisión basados en listas hechas de palabras indicativas de subjetividad, para extraer las oraciones subjetivas. En la primera fase del algoritmo, las frases con alto nivel de confianza son etiquetadas por dos clasificadores (primero, se etiquetan las subjetivas con alto nivel de confianza, y luego las objetivas con alto nivel de confianza). Las frases que no tengan un alto nivel de confianza de pertenecer a una u otra categoría quedan sin etiquetar en esta primera fase. \newline
En la segunda etapa del algoritmo, con los datos etiquetados obtenidos en la fase anterior se entrena un algoritmo de extracción que genera patrones para oraciones subjetivas, patrones que después son usados para buscar más sentencias subjetivas en el texto. Tras procesar todo el conjunto de datos de entrenamiento, se ordenan los patrones extraídos basándose en su ocurrencia, entre otras condiciones, y se toman los mejores para la siguiente iteración del análisis. \newline

A diferencia de la técnica anterior, \citet{yu2003towards} presentaron un trabajo en el que se clasificaba la frase en objetiva o subjetiva, pero también la orientación de las frases subjetivas(positiva,negativa o neutral). Para la primera, los autores presentan resultados para  \textsf{detección de similaridad en oraciones}, \textsf{naive bayes} y \textsf{naive bayes multiclase}. Para la segunda tarea, emplean una técnica similar a la de \citet{turney2002thumbs}.  
\subsection{Análisis de sentimientos a nivel de aspecto}
Este nivel de análisis es el más detallado, lo que lo convierte en el más útil pero también el más complicado, ya que el objetivo no es solo determinar qué frases son objetivas o subjetivas y si estas últimas tienen orientación positiva, negativa o neutral, sino que también tiene como objetivo detectar qué es esactamente lo que le gusta o no al autor. \newline
Una de las primeras soluciones más conocidas a este problema fue \citet{hu2004mining}, un enfoque basado en el léxico que utilizaba la mayor frecuencia de las entidades, aspectos o servicios. Sobre éste se publica una mejora 4 años más tarde \citet{ding2008holistic}, presentando así un método que funciona bastante bien en la práctica y consta de cuatro pasos:
\begin{itemize}
\item Paso 1. Marcar expresiones de sentimientos: consiste en marcar todas las expresiones de sentimientos en cada frase que contengan uno o más aspectos con +1 o -1. Por ejemplo: \textsl{"el altavoz de este teléfono no es bueno"} sería marcada con un (+1) dado que "bueno" es una palabra asociada a polaridad positiva.
\item Paso 2. Aplicar desplazadores de sentimientos: esto son, palabras o frases que pueden cambiar la orientación del sentimiento. Por ejemplo, "no" es un desplazador. Ahora la frase anterior sería marcada con (-1).
\item Paso 3. Manejo de palabras y frases adversativas: palabras y frases que indican contrariedad necesitan ser manejadas, ya que suelen cambiar la orientación de los sentimientos. Por ejemplo, "pero" o"sin embargo"..son conjunciones adversativas. Un ejemplo de manejo sería \textsl{"el altavoz de este teléfono no es bueno (-1), sin embargo la cámara es estupenda (+1)"}
\item paso 4. Agregar puntuación de los sentimientos: para ello se suele aplicar una función como 
\[puntuacion(a_{i},s)=\sum_{se_{j}\epsilon s}{}\frac{se_{j}.ss}{dist(se_{j},a_{i})}\]
donde $se_{j}$ es la expresión de un sentimiento en la frase $s$, $a_{i}$ es el aspecto(objeto, servicio...) i-ésimo de la frase $s$ , $se_{j}.ss$ es la puntuación del sentimiento $se_{i}$  y $dist(se_{j},a_{i})$ es la distancia entre el aspecto $a_{i}$ y el sentimiento $se_{j}$ en la oración $s$.
\end{itemize}  
Si la puntuación final es positiva, entonces la opinión sobre el aspecto $a_{i}$ en la frase $s$ es positivo. Si la puntuación es negativa, la opinión sobre el aspecto es negativa. Si es 0, la opinión sobre ese aspecto es neutral.\newline
También se han planteado métodos que usan aprendizaje automático en este nivel de análisis, como por ejemplo \citet{jiang2011target} que emplea un árbol de parseo sintáctico para generar un conjunto de características que representen algunas relaciones sintácticas de la entidad o aspecto objetivo, y otras palabras. 


